{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa65863-1cb8-43e3-9150-dd0ccd727c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74184e42-1176-482d-9dc4-c10ace9f0c5a",
   "metadata": {},
   "source": [
    "Today, let's look at Amtrak arrival and departure data provided by [AMSAD](https://juckins.net/amtrak_status/archive/html/home.php), and use it to predict arrival delays.\n",
    "\n",
    "I'd like to thank Chris, the retainer of ASMAD for helping provide the data, and for his support answering by various questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1a2105-48e6-4bd3-a910-01de1b8e3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.read_csv('status.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea47da-c9be-4faf-a4a1-024e1f2e46df",
   "metadata": {},
   "source": [
    "**Column Names & Descriptions**\n",
    "- no - Train Number\n",
    "- origin_date\n",
    "- sta_no - Station Number (nth station of the train line for that day)\n",
    "- station - Station Name\n",
    "- schArDay - Scheduled Arrival Day, where 1 is same day, 2 is the next day, and 3 is 2 days after departure\n",
    "- schAr - Scheduled Arrival\n",
    "- actAr - Actual Arrival\n",
    "- schDpDay - Scheduled Departure Day\n",
    "- schDp - Scheduled Departure\n",
    "- actDp - Actual Departure\n",
    "- d_ar - Delay (Arrival)\n",
    "- d_dp - Delay (Departure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb93fdb-446f-43b6-ac74-2f6b6bd1e31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>sta_no</th>\n",
       "      <th>station</th>\n",
       "      <th>schArDay</th>\n",
       "      <th>schAr</th>\n",
       "      <th>actAr</th>\n",
       "      <th>schDpDay</th>\n",
       "      <th>schDp</th>\n",
       "      <th>actDp</th>\n",
       "      <th>d_ar</th>\n",
       "      <th>d_dp</th>\n",
       "      <th>comments</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 16:25:00</td>\n",
       "      <td>4:25PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Departed:  On time.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 16:36:00</td>\n",
       "      <td>4:40PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Departed:  4 minutes late.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BWI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 16:51:00</td>\n",
       "      <td>4:56PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Departed:  5 minutes late.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 17:05:00</td>\n",
       "      <td>5:08PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 17:07:00</td>\n",
       "      <td>5:11PM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Arrived:  3 minutes late.            |  Depart...</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WIL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 17:53:00</td>\n",
       "      <td>5:54PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 17:55:00</td>\n",
       "      <td>5:57PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Arrived:  1 minute late.             |  Depart...</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    no origin_date  sta_no station  schArDay                schAr   actAr  \\\n",
       "0  126  2018-01-01     NaN     WAS       NaN                  NaN     NaN   \n",
       "1  126  2018-01-01     NaN     NCR       NaN                  NaN     NaN   \n",
       "2  126  2018-01-01     NaN     BWI       NaN                  NaN     NaN   \n",
       "3  126  2018-01-01     NaN     BAL       1.0  2018-01-01 17:05:00  5:08PM   \n",
       "4  126  2018-01-01     NaN     WIL       1.0  2018-01-01 17:53:00  5:54PM   \n",
       "\n",
       "   schDpDay                schDp   actDp  d_ar  d_dp  \\\n",
       "0       1.0  2018-01-01 16:25:00  4:25PM   NaN   0.0   \n",
       "1       1.0  2018-01-01 16:36:00  4:40PM   NaN   4.0   \n",
       "2       1.0  2018-01-01 16:51:00  4:56PM   NaN   5.0   \n",
       "3       1.0  2018-01-01 17:07:00  5:11PM   3.0   4.0   \n",
       "4       1.0  2018-01-01 17:55:00  5:57PM   1.0   2.0   \n",
       "\n",
       "                                            comments              updated  \n",
       "0                                Departed:  On time.  2019-03-26 00:00:00  \n",
       "1                         Departed:  4 minutes late.  2019-03-26 00:00:00  \n",
       "2                         Departed:  5 minutes late.  2019-03-26 00:00:00  \n",
       "3  Arrived:  3 minutes late.            |  Depart...  2019-03-26 00:00:00  \n",
       "4  Arrived:  1 minute late.             |  Depart...  2019-03-26 00:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bcaf7e7-fa99-475a-9069-ba6e3a06ddbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8978660 entries, 0 to 8978659\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   no           int64  \n",
      " 1   origin_date  object \n",
      " 2   sta_no       float64\n",
      " 3   station      object \n",
      " 4   schArDay     float64\n",
      " 5   schAr        object \n",
      " 6   actAr        object \n",
      " 7   schDpDay     float64\n",
      " 8   schDp        object \n",
      " 9   actDp        object \n",
      " 10  d_ar         float64\n",
      " 11  d_dp         float64\n",
      " 12  comments     object \n",
      " 13  updated      object \n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 959.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218f8dbc-2eb3-4e59-8fb7-c2869f306a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                   0\n",
       "origin_date          0\n",
       "station              0\n",
       "updated              0\n",
       "comments        107932\n",
       "schDpDay        637048\n",
       "schDp           637049\n",
       "d_dp            930917\n",
       "actDp           931258\n",
       "sta_no         6293892\n",
       "schArDay       6774781\n",
       "schAr          6774899\n",
       "actAr          6826568\n",
       "d_ar           6827100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09573f96-0615-4596-a1cf-e26a4fb87eac",
   "metadata": {},
   "source": [
    "<h2>Imputation<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803c4aa-1213-4b9e-a252-01f6ba9fb6e2",
   "metadata": {},
   "source": [
    "<h3>Station Number<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d7b9b2-4e33-457a-ae88-0fa18ae0076b",
   "metadata": {},
   "source": [
    "Although we always have train number and station name, in the majority of places we have no station number. My hunch is that `sta_no` will be an important feature because according to data pulled from ASMAD, the further down you are on a given train ride [the larger your average delay.](https://juckins.net/amtrak_status/archive/html/average_delays.php?train_num=14&date_start=09%2F10%2F2024&date_end=10%2F10%2F2024&df1=1&df2=1&df3=1&df4=1&df5=1&df6=1&df7=1&stat=avg&chartsize=2&dfon=1) Let's clean `sta_no` up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3250f5-9d8e-42a4-85ae-a7fa213dd3e2",
   "metadata": {},
   "source": [
    "Since `schDp` is available in the vast majority of cases (only 7% missing), we can simply complete the sequences by ordering on that.\n",
    "\n",
    "In cases where schDp is unavailable, let's not make an imputation for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65a76c7-d87e-4cf6-aa75-3b3be1d1a185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0709514560079121"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.schDp[df.schDp.isna()])/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c973849c-d49a-48de-a220-faf3133783a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637049"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.schDp[df.schDp.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669164ed-6356-48f0-ba7b-374a9e7e3f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/8dj_s7d12jn3gqzqszzgtfnr0000gn/T/ipykernel_44406/4047207473.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_null_schDp['sta_no'] = df_non_null_schDp.groupby(['no', 'origin_date']).cumcount() + 1\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by=['no', 'origin_date','schDpDay','schDp'])\n",
    "\n",
    "# Filter only rows where 'schDp' is not null and assign sequential 'sta_no'\n",
    "# Keep track of schDpDay for multi-day journeys\n",
    "df_non_null_schDp = df[df['schDp'].notna()]\n",
    "\n",
    "df_non_null_schDp['sta_no'] = df_non_null_schDp.groupby(['no', 'origin_date']).cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9d07a4-a8c4-4d57-9cdd-a43dfa50313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_no_mapping = (\n",
    "    df_non_null_schDp.dropna(subset=['sta_no'])\n",
    "    .set_index(['no', 'origin_date', 'schDp', 'schDpDay'])['sta_no']\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Step 2: Apply the mapping to fill 'sta_no' in the original DataFrame\n",
    "# For each row, check if there’s a corresponding value in the mapping dictionary\n",
    "df['sta_no'] = df.apply(\n",
    "    lambda row: sta_no_mapping.get((row['no'], row['origin_date'], row['schDp'], row['schDpDay']), row['sta_no']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aae2e2b-a87e-4535-9e74-3268a2eccc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049852650618243705"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.sta_no[df.sta_no.isna()])/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053341e2-5398-4013-a77e-a68a0b30568f",
   "metadata": {},
   "source": [
    "Terminus stations have no `schDp`, but they do have `schAr`. The other stations generally have `schDp` but no `schAr`. In such places, where the previous row is also the same `no` and `origin_date`, let's impute the previous station number plus 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c75b18-d51e-4296-89f4-f594d1e3dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_schDp'] = df.schDp.shift(1)\n",
    "df['prev_schAr'] = df.schAr.shift(1)\n",
    "df['prev_no'] = df.no.shift(1)\n",
    "df['prev_sta_no'] = df.sta_no.shift(1)\n",
    "df['prev_origin_date'] = df.origin_date.shift(1)\n",
    "\n",
    "terminus_conditions = (\n",
    "    df['sta_no'].isna() &\n",
    "    df['schDp'].isna() &\n",
    "    df['schAr'].notna() &\n",
    "    (df['no'] == df['no'].shift(1)) &\n",
    "    (df['origin_date'] == df['origin_date'].shift(1))\n",
    ")\n",
    "\n",
    "df.loc[terminus_conditions,'sta_no'] = df.loc[terminus_conditions,'prev_sta_no'] +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c636e-f2f9-4de7-bc62-7ac863081853",
   "metadata": {},
   "source": [
    "If we check the comments, we see that the remaining terminus stations with no `sta_no` are like that because the train never got there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee305127-fc10-4bdb-8ab3-9b7e5b7e7612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>sta_no</th>\n",
       "      <th>station</th>\n",
       "      <th>schArDay</th>\n",
       "      <th>schAr</th>\n",
       "      <th>actAr</th>\n",
       "      <th>schDpDay</th>\n",
       "      <th>schDp</th>\n",
       "      <th>actDp</th>\n",
       "      <th>d_ar</th>\n",
       "      <th>d_dp</th>\n",
       "      <th>comments</th>\n",
       "      <th>updated</th>\n",
       "      <th>prev_schDp</th>\n",
       "      <th>prev_schAr</th>\n",
       "      <th>prev_no</th>\n",
       "      <th>prev_sta_no</th>\n",
       "      <th>prev_origin_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5510070</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-05-02 05:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT Station Stop Canceled</td>\n",
       "      <td>2022-05-05 04:06:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-01 13:22:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298318</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-07-16 21:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CT Station Stop Canceled</td>\n",
       "      <td>2019-07-17 04:06:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-16 06:25:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682848</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-08-25 21:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CT Station Stop Canceled</td>\n",
       "      <td>2021-01-25 09:36:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-25 04:50:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700463</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-09-01 21:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CT Station Stop Canceled</td>\n",
       "      <td>2021-01-25 09:36:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-01 04:50:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802447</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-10-09 21:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CT Station Stop Canceled</td>\n",
       "      <td>2021-01-25 09:36:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-09 04:50:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         no origin_date  sta_no station  schArDay                schAr actAr  \\\n",
       "5510070   1  2022-04-30     NaN     LAX       3.0  2022-05-02 05:35:00   NaN   \n",
       "2298318   2  2019-07-14     NaN     NOL       3.0  2019-07-16 21:40:00   NaN   \n",
       "3682848   2  2020-08-23     NaN     NOL       3.0  2020-08-25 21:40:00   NaN   \n",
       "3700463   2  2020-08-30     NaN     NOL       3.0  2020-09-01 21:40:00   NaN   \n",
       "3802447   2  2020-10-07     NaN     NOL       3.0  2020-10-09 21:40:00   NaN   \n",
       "\n",
       "         schDpDay schDp actDp  d_ar  d_dp                  comments  \\\n",
       "5510070       NaN   NaN   NaN   NaN   NaN  PT Station Stop Canceled   \n",
       "2298318       NaN   NaN   NaN   NaN   NaN  CT Station Stop Canceled   \n",
       "3682848       NaN   NaN   NaN   NaN   NaN  CT Station Stop Canceled   \n",
       "3700463       NaN   NaN   NaN   NaN   NaN  CT Station Stop Canceled   \n",
       "3802447       NaN   NaN   NaN   NaN   NaN  CT Station Stop Canceled   \n",
       "\n",
       "                     updated prev_schDp           prev_schAr  prev_no  \\\n",
       "5510070  2022-05-05 04:06:23        NaN  2022-05-01 13:22:00      1.0   \n",
       "2298318  2019-07-17 04:06:32        NaN  2019-07-16 06:25:00      2.0   \n",
       "3682848  2021-01-25 09:36:25        NaN  2020-08-25 04:50:00      2.0   \n",
       "3700463  2021-01-25 09:36:25        NaN  2020-09-01 04:50:00      2.0   \n",
       "3802447  2021-01-25 09:36:28        NaN  2020-10-09 04:50:00      2.0   \n",
       "\n",
       "         prev_sta_no prev_origin_date  \n",
       "5510070          NaN       2022-04-30  \n",
       "2298318          NaN       2019-07-14  \n",
       "3682848          NaN       2020-08-23  \n",
       "3700463          NaN       2020-08-30  \n",
       "3802447          NaN       2020-10-07  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[terminus_conditions & (df.sta_no.isna())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87fc2c42-57f4-4ef1-ba97-0948f4948fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.sta_no[df.sta_no.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f4cf0b-b416-4c58-a85f-96fcc8320dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013888486700688077"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.sta_no[df.sta_no.isna()])/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c31ce-9543-4fb0-8de4-c8f8c5d3f7f1",
   "metadata": {},
   "source": [
    "The vast number `sta_no` values have been imputed! We can drop the remaining rows in this case, because we are trying to predict delays, not canellations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb395de-faa0-434a-9375-39e861641b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['sta_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e925a76d-4511-4afa-b7ef-9d2924e5182e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                        0\n",
       "origin_date               0\n",
       "sta_no                    0\n",
       "station                   0\n",
       "updated                   0\n",
       "prev_no                   1\n",
       "prev_origin_date          1\n",
       "comments             107903\n",
       "prev_sta_no          446377\n",
       "schDpDay             635801\n",
       "schDp                635802\n",
       "prev_schDp           635815\n",
       "d_dp                 929672\n",
       "actDp                930013\n",
       "schArDay            6774767\n",
       "prev_schAr          6774873\n",
       "schAr               6774885\n",
       "actAr               6825334\n",
       "d_ar                6825866\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28f404-ad62-4a0e-bc8d-3a6df43f764b",
   "metadata": {},
   "source": [
    "<h3>Arrival & Departure Times, Delays<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e611d8-d77c-4fc9-a5d4-ed6c6d4847b9",
   "metadata": {},
   "source": [
    "There's a lot of information missing about arrival times. About 75% is missing, in fact (although it is reliably there for terminus stations)! This is a constraint of the data supplied by Amtrak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7699b2ee-2761-4224-b8c3-fc09d52ba5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7546589423924241)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schAr.isna().sum()/len(df.schAr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c669d9-3c7c-424d-8703-5c68685f1f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.760278490028252)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.actAr.isna().sum()/len(df.actAr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f448b2-01cb-4c7a-9d9a-c45a260dd310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.760337749861792)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.d_ar.isna().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25de8e-61de-4483-8224-2ab89ac45504",
   "metadata": {},
   "source": [
    "<h4>schAr<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a08f2e-2792-4b02-88ef-6e790febcfe3",
   "metadata": {},
   "source": [
    "Now, let's make some imputations for the missing scheduled arrival values using previous values for the same train, station, and day of the week. Importantly, each train has a Weekday schedule, a Saturday schedule, and a Sunday schedule. If there is no non-null value available for that specific weekday, then we want to expand our search to check for other weekdays. If multiple values are availble for the train, station, and day of week, we'll choose the most recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8bff042-3dac-49d5-9d8f-983aeeb24a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/8dj_s7d12jn3gqzqszzgtfnr0000gn/T/ipykernel_44406/1243343594.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['actAr'] = pd.to_datetime(df['actAr'], errors='coerce')\n",
      "/var/folders/4y/8dj_s7d12jn3gqzqszzgtfnr0000gn/T/ipykernel_44406/1243343594.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['actDp'] = pd.to_datetime(df['actDp'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "#Convert these columns to datetime\n",
    "df['origin_date'] = pd.to_datetime(df['origin_date'], errors='coerce')\n",
    "df['schAr'] = pd.to_datetime(df['schAr'], errors='coerce')\n",
    "df['actAr'] = pd.to_datetime(df['actAr'], errors='coerce')\n",
    "df['schDp'] = pd.to_datetime(df['schDp'], errors='coerce')\n",
    "df['actDp'] = pd.to_datetime(df['actDp'], errors='coerce')\n",
    "\n",
    "#Add a column for the day of the week (0 = Monday, ..., 6 = Sunday)\n",
    "df['origin_day_of_week'] = df['origin_date'].dt.dayofweek\n",
    "\n",
    "# Sort values by 'train number', 'station number', and 'schAr' to ensure proper order\n",
    "df = df.sort_values(by=['no', 'origin_date','sta_no'])\n",
    "\n",
    "# Group by 'train number', 'station number', and 'day of week'\n",
    "# Fill missing 'schAr' with forward-fill within each group to fill NaNs with most recent non-null value\n",
    "df['schAr_filled'] = df.groupby(['no', 'sta_no', 'origin_day_of_week'])['schAr'].transform(lambda x: x.ffill())\n",
    "\n",
    "# Handle cases where weekdays (day_of_week < 5) should share schedules\n",
    "# First, create a mask for weekdays only\n",
    "weekday_mask = df['origin_day_of_week'] < 5\n",
    "\n",
    "# Now, fill within weekdays (Monday-Friday) across all groups by train number and station number\n",
    "df.loc[weekday_mask, 'schAr_filled'] = df[weekday_mask].groupby(['no', 'sta_no'])['schAr_filled'].transform(lambda x: x.ffill())\n",
    "\n",
    "# Replace original 'schAr' with filled values\n",
    "df['schAr'] = df['schAr'].fillna(df['schAr_filled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c1fc472-687f-4bce-b29a-5becb66b9134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.31403456652824147)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schAr.isna().sum()/len(df.schAr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6ca2b5-a1b4-405d-8901-544d608523b7",
   "metadata": {},
   "source": [
    "We've reduced missing values for `schAr` from 75% to 31%!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eebdda-149f-4788-afc9-8c8b892f6f92",
   "metadata": {},
   "source": [
    "<h4>actAr & actDp<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb63bf1-4e4b-4390-a49c-e006325f0027",
   "metadata": {},
   "source": [
    "In order to reduce the number of NaN values for `actAr`, let's assume it's the same as `actDp` in all places where the train left on time. This may miss cases where the train arrived early (not logged) and then waited until the scheduled departure time to depart, but I'm going to assume that's fine.\n",
    "\n",
    "In such cases, we'll infer that `actAr = schAr = actDp`, and that d_ar is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8bac9a8-ba62-4e11-aa47-058ed38c7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a condition where actAr and schAr are NaN and d_dp is 0\n",
    "no_arr = df['actAr'].isnull() & df['schAr'].isnull() & df['d_ar'].isnull() & (df['d_dp'] == 0)\n",
    "\n",
    "\n",
    "# Assign actDp to both actAr and schAr, and set d_ar to 0 for rows that satisfy the condition\n",
    "df.loc[no_arr, ['actAr', 'schAr']] = df['actDp']\n",
    "df.loc[no_arr, 'd_ar'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bce00321-b2df-4708-9049-85d275a3ff66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903780, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[no_arr].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032822b-4de6-491e-b47f-9693e4517efc",
   "metadata": {},
   "source": [
    "In cases where `actDp` is actually BEFORE `schAr`, we can infer that the train arrived early and departed early, i.e. `actAr = actDp < schAr`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "554a303c-99b8-40e1-8e77-b2fc19ae329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['actDp'] < df['schAr'], 'actAr'] = df['actDp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86305a0-0f9f-407d-bbac-c3762e2ab050",
   "metadata": {},
   "source": [
    "Let's check the NaNs now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9455c8d8-72f2-4f3f-bf42-9a09e36df02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.21339922759485389)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schAr.isna().sum()/len(df.schAr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b37afc8-8b65-4384-8e40-0b2edcacb133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6596431510948644)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.actAr.isna().sum()/len(df.actAr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7d2b6c2-3c75-41c5-8175-2c378092a86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6596650950557805)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.d_ar.isna().sum()/len(df.d_ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5eeb5c-6d92-43f1-b7a0-084f97270a88",
   "metadata": {},
   "source": [
    "We reduced the NaN values for `schAr` from about 75% to 3%, and `actAr` and `d_ar` to 66%. Let's spot check a couple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89ea177a-7577-4589-a40a-17eb73a86064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>sta_no</th>\n",
       "      <th>station</th>\n",
       "      <th>schArDay</th>\n",
       "      <th>schAr</th>\n",
       "      <th>actAr</th>\n",
       "      <th>schDpDay</th>\n",
       "      <th>schDp</th>\n",
       "      <th>actDp</th>\n",
       "      <th>...</th>\n",
       "      <th>d_dp</th>\n",
       "      <th>comments</th>\n",
       "      <th>updated</th>\n",
       "      <th>prev_schDp</th>\n",
       "      <th>prev_schAr</th>\n",
       "      <th>prev_no</th>\n",
       "      <th>prev_sta_no</th>\n",
       "      <th>prev_origin_date</th>\n",
       "      <th>origin_day_of_week</th>\n",
       "      <th>schAr_filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>753207</th>\n",
       "      <td>354</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ROY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-15 00:18:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-07-05 00:18:00</td>\n",
       "      <td>2024-10-12 01:21:00</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Departed:  1 hour, 3 minutes late.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "      <td>2018-07-04 23:54:00</td>\n",
       "      <td>2018-07-04 23:54:00</td>\n",
       "      <td>354.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-15 00:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279879</th>\n",
       "      <td>86</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ASD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-03-05 06:13:00</td>\n",
       "      <td>2024-10-12 06:20:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Departed:  7 minutes late.</td>\n",
       "      <td>2021-01-25 11:40:00</td>\n",
       "      <td>2020-03-05 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874043</th>\n",
       "      <td>710</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MCD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-05 10:45:00</td>\n",
       "      <td>2024-10-12 10:51:00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Departed:  6 minutes late.</td>\n",
       "      <td>2021-01-25 11:17:27</td>\n",
       "      <td>2020-11-05 10:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385198</th>\n",
       "      <td>56</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>19.0</td>\n",
       "      <td>GFD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-01 16:22:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-03-23 16:22:00</td>\n",
       "      <td>2024-10-12 16:22:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Departed:  On time.</td>\n",
       "      <td>2022-03-24 04:27:59</td>\n",
       "      <td>2022-03-23 15:57:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01 16:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928017</th>\n",
       "      <td>684</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>11.0</td>\n",
       "      <td>WOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-26 14:25:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-08-16 14:04:00</td>\n",
       "      <td>2024-10-12 14:10:00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Departed:  6 minutes late.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "      <td>2018-08-16 13:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>684.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-26 14:25:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          no origin_date  sta_no station  schArDay               schAr actAr  \\\n",
       "753207   354  2018-07-04    12.0     ROY       NaN 2018-03-15 00:18:00   NaT   \n",
       "3279879   86  2020-03-05     2.0     ASD       NaN                 NaT   NaT   \n",
       "3874043  710  2020-11-05     9.0     MCD       NaN                 NaT   NaT   \n",
       "5385198   56  2022-03-23    19.0     GFD       NaN 2021-12-01 16:22:00   NaT   \n",
       "928017   684  2018-08-16    11.0     WOB       NaN 2018-04-26 14:25:00   NaT   \n",
       "\n",
       "         schDpDay               schDp               actDp  ...  d_dp  \\\n",
       "753207        2.0 2018-07-05 00:18:00 2024-10-12 01:21:00  ...  63.0   \n",
       "3279879       1.0 2020-03-05 06:13:00 2024-10-12 06:20:00  ...   7.0   \n",
       "3874043       1.0 2020-11-05 10:45:00 2024-10-12 10:51:00  ...   6.0   \n",
       "5385198       1.0 2022-03-23 16:22:00 2024-10-12 16:22:00  ...   0.0   \n",
       "928017        1.0 2018-08-16 14:04:00 2024-10-12 14:10:00  ...   6.0   \n",
       "\n",
       "                                   comments              updated  \\\n",
       "753207   Departed:  1 hour, 3 minutes late.  2019-03-26 00:00:00   \n",
       "3279879          Departed:  7 minutes late.  2021-01-25 11:40:00   \n",
       "3874043          Departed:  6 minutes late.  2021-01-25 11:17:27   \n",
       "5385198                 Departed:  On time.  2022-03-24 04:27:59   \n",
       "928017           Departed:  6 minutes late.  2019-03-26 00:00:00   \n",
       "\n",
       "                  prev_schDp           prev_schAr prev_no  prev_sta_no  \\\n",
       "753207   2018-07-04 23:54:00  2018-07-04 23:54:00   354.0         11.0   \n",
       "3279879  2020-03-05 06:00:00                  NaN    86.0          1.0   \n",
       "3874043  2020-11-05 10:12:00                  NaN   710.0          8.0   \n",
       "5385198  2022-03-23 15:57:00                  NaN    56.0         18.0   \n",
       "928017   2018-08-16 13:35:00                  NaN   684.0         10.0   \n",
       "\n",
       "         prev_origin_date origin_day_of_week        schAr_filled  \n",
       "753207         2018-07-04                  2 2018-03-15 00:18:00  \n",
       "3279879        2020-03-05                  3                 NaT  \n",
       "3874043        2020-11-05                  3                 NaT  \n",
       "5385198        2022-03-23                  2 2021-12-01 16:22:00  \n",
       "928017         2018-08-16                  3 2018-04-26 14:25:00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a906d01-7647-4433-8e3c-13eaf6d9c98e",
   "metadata": {},
   "source": [
    "<h3>More on `d_ar`<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74dacabe-f702-4ec6-add9-a2ec23d32546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                          0\n",
       "origin_date                 0\n",
       "sta_no                      0\n",
       "station                     0\n",
       "origin_day_of_week          0\n",
       "updated                     0\n",
       "prev_origin_date            1\n",
       "prev_no                     1\n",
       "comments               107903\n",
       "prev_sta_no            446377\n",
       "schDpDay               635801\n",
       "schDp                  635803\n",
       "prev_schDp             635815\n",
       "d_dp                   929672\n",
       "actDp                  930013\n",
       "schAr                 1915773\n",
       "schAr_filled          2819218\n",
       "actAr                 5921889\n",
       "d_ar                  5922086\n",
       "schArDay              6774767\n",
       "prev_schAr            6774873\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56892ced-a7b9-4227-bdc6-79a166cc753b",
   "metadata": {},
   "source": [
    "Arrival delay, `d_ar` is the variable we are going to predict, so it's crucial that we minimize the number of missing values in a way that we can trust. For pairs of stops where there is a departure delay and arrival information is available, is there a predictable relationship? Let's try to regress `d_ar` on `d_dp` of the previous station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9926138-a55a-4ef4-9736-737bdad82625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9531905243618051)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort the dataframe by train number and station number to ensure correct sequence\n",
    "df = df.sort_values(by=['no', 'origin_date','sta_no'])\n",
    "\n",
    "# Create a mask to identify where train number resets\n",
    "reset_mask = (df['no'] != df['no'].shift(1))\n",
    "\n",
    "# Shift the d_dp column by one row to align with the next station's actAr\n",
    "df['prev_d_dp'] = df['d_dp'].shift(1)\n",
    "\n",
    "# Invalidate the prev_d_Dp values where no reset occurs\n",
    "df.loc[reset_mask, 'prev_d_dp'] = pd.NA \n",
    "\n",
    "valid_rows = df[(df['d_ar'].isnull()==False)&(df['prev_d_dp'].isnull()==False)]\n",
    "\n",
    "# Optional: Analyze the relationship\n",
    "# For example, you can check the correlation between actAr and prev_actDp\n",
    "correlation = valid_rows['d_ar'].astype('int64').corr(valid_rows['prev_d_dp'].astype('int64'))\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5416d56-4ecc-4d44-b9cc-af88aa8def28",
   "metadata": {},
   "source": [
    "95%!\n",
    "\n",
    "Now, for the sake of train error purposes, let's keep our original `d_ar` values as they are for now with only our rule of thumb imputations.\n",
    "\n",
    "Since we know that, where both are available, `d_ar` is 95% correlated with `prev_d_dp`, let's make a `d_ar_filled` in which we predict based on the equation `d_ar = beta1 * prev_d_dp + beta2 * c + error`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f468c-8f11-467a-9e0a-b769c139f218",
   "metadata": {},
   "source": [
    "Let's check the coverage of observations where `d_ar` and `prev_d_dp` are both non-NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0d93bf3-e780-41c7-ba51-60bbd4e59900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2521750, 22)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.d_ar.isnull() == False)&(df.prev_d_dp.isnull() == False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4f5e84c-d0c1-4147-992e-40de99a9cb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28089940832620713"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.d_ar.isnull() == False)&(df.prev_d_dp.isnull() == False)].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9d9e2-b4c5-4f13-9481-2ea920c0d623",
   "metadata": {},
   "source": [
    "Only about 28%. We should proceed with caution before using this to impute on every single train and station. Let's use some additional domain knowledge I got from the maintainer of the [Status Maps Database](https://juckins.net/amtrak_status/archive/html/home.php).\n",
    "\n",
    "A key place where `d_ar` will have a weaker correlation to `prev_d_dp` is in places where Amtrak puts recovery time or \"padding\" between certain stations. For example, there is a sizeable pad on the Coast Starlight #14 between Salem and Portland. The train might [leave Salem late and still arrive Portland early](https://asm.transitdocs.com/train/2024/9/5/A/14).\n",
    "\n",
    "It's difficult to catch all the cases of padding, but we can get pretty far with two observations:\n",
    "\n",
    "- It happens more on overnight trains, allowing the passengers to rest instead of arriving at their destination early and waking everyone up.\n",
    "- It tends to happen between penultimate stations and termini so that there are more on-time arrivals at termini. (In fact, it's a leftover practice from when on-time performance metrics weren't kept at the individual stations, but just at the terminus. More recently, all stops are considered when calculating on-time performance, and the practice has diminished somewhat, but hasn't gone away.)\n",
    "\n",
    "Given that, it seems safest to exclude **overnight** trains and **terminus** stations from our imputation process. Let's check how significant these cases are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e276aa1-1b00-4ffd-8858-74ebe5f70d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'no', 'origin_date', and 'sta_no'\n",
    "df = df.sort_values(by=['no', 'origin_date', 'sta_no'])\n",
    "\n",
    "#remove NaN values\n",
    "df_term = df.dropna(subset=['no', 'origin_date','sta_no'])\n",
    "\n",
    "terminus_indices = df_term.groupby(['no', 'origin_date'])['sta_no'].idxmax()\n",
    "\n",
    "# Group by 'no' and 'origin_date', and select the row with the maximum 'sta_no' within each group\n",
    "df_term = df_term.loc[terminus_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb4ad322-2388-483d-8414-c2ecedc2f0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07075991713871245"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_term.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cb2b913-e97e-467d-b4a3-ccff4af2413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overnight_journeys = df.groupby(['no', 'origin_date']).filter(lambda x: (x['schArDay'] > 1).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6910f0e-f84d-4d0a-9a5f-a1e45f56305c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22908381289799187"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overnight_journeys.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b4cbaa8-802c-4ebb-8106-51074d7980a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29984373003670434"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_term.shape[0] + overnight_journeys.shape[0])/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bcdc8-9bfa-4ac1-b854-a13b7137f81f",
   "metadata": {},
   "source": [
    "Looks like 30% of stops fall into one of these edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3232774-7f93-4099-a99a-bf17f7af66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by filling all existing values\n",
    "df['d_ar_filled'] = df.d_ar\n",
    "\n",
    "exclude_indices = set(df_term.index).union(set(overnight_journeys.index))\n",
    "\n",
    "# Prepare data for regression where both 'd_ar' and 'prev_d_dp' are not NaN\n",
    "# Additionally, exclude indices from terminus_stations and overnight_journeys\n",
    "train_data = df.dropna(subset=['d_ar', 'prev_d_dp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6788a64c-3232-4d55-9d8b-6d1a82434e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2521750, 23)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02608206-4073-4d6f-930d-d0631f2a2bca",
   "metadata": {},
   "source": [
    "Ultimately, test error will determine if we have a problem here, but caution seems warranted because we are about to imput about 7M values in our `y_train` based on a relationship observed in only 2.4M values. \n",
    "\n",
    "If we don't have any existing `d_ar` data **at all** for a given train number, it seems a bit cavalier to assume it is going to have the same strong correlation between `d_ar` and `prev_d_dp`. \n",
    "\n",
    "Let's check if all train (as in locomotive) numbers are represented in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0759c351-8e64-4690-b727-d79d26c9fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_no_values = df[~df['no'].isin(train_data['no'])]['no'].unique()\n",
    "missing_no_values = pd.Series(missing_no_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c049b36-4896-4055-8579-77e4b7e807ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     377\n",
       "1     515\n",
       "2     533\n",
       "3     922\n",
       "4    1297\n",
       "5    1448\n",
       "6    3596\n",
       "7    9992\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_no_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dac5c78-868e-44c4-bd54-e6010b17d771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    9992\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_no_values[missing_no_values.isin(overnight_journeys['no'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f25c1d-f780-4a82-b008-6e94882abba0",
   "metadata": {},
   "source": [
    "From spot checks on [Rail Rat](https://railrat.net/trains/), the only trains in this list still operational are 533, 922, 1297, and 1448. Others are one-off train numbers created in cases where track work makes it such that two trains of the same number actually end up running on the same day. To prevent inconsistencies, Amtrak creates a new number for the second train. Manual inspection found that each train number has at least one valid `d_ar` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f842fac-b799-4483-a944-0500291d2200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>d_ar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739811</th>\n",
       "      <td>1448</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739812</th>\n",
       "      <td>1448</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739813</th>\n",
       "      <td>1448</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739814</th>\n",
       "      <td>1448</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739815</th>\n",
       "      <td>1448</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          no origin_date   d_ar\n",
       "739811  1448  2018-05-25  110.0\n",
       "739812  1448  2018-05-25    NaN\n",
       "739813  1448  2018-05-25    NaN\n",
       "739814  1448  2018-05-25    NaN\n",
       "739815  1448  2018-05-25  126.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.no.isin([533, 922, 1297, 1448]),['no','origin_date','d_ar']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059cd09-211f-4bf3-8ad0-210c9fc100ca",
   "metadata": {},
   "source": [
    "For now, we'll proceed to impute the rest of the values, even for trains for which we have no observed `d_ar` values, as long as they are not overnight trains.\n",
    "\n",
    "Perhaps for overnight trains, we can make a separate correlation check and regression imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57d49b09-1a90-42a9-8dc4-43c7bfe114a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9549752855446062)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overnight_journeys['d_ar'].corr(overnight_journeys['prev_d_dp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d5dae-7b02-4e49-9e7d-d237bec36a2f",
   "metadata": {},
   "source": [
    "\n",
    "Oh wow, It's still very tight! What about for teminus stations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "058c8b1c-54a1-43b2-80e7-c12761a4d070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9277966755584122)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_term['d_ar'].corr(df_term['prev_d_dp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f4967-31ad-4e5d-8216-35f3fb3bdfc4",
   "metadata": {},
   "source": [
    "Not quite as high, but I'm still willing to live with 92% correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191a71d-5187-43ed-9617-f4779c60b401",
   "metadata": {},
   "source": [
    "Let's skip the exclusion for now, and we can always return to this part if prediction accuracy for overnight and terminus stations is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71c76040-ddcf-455d-b275-1d735d05f2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2521750, 23)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee5ae8e2-7372-4e59-8393-49bf30b5fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X_train = train_data[['prev_d_dp']].values  # Feature\n",
    "y_train = train_data['d_ar'].values         # Target\n",
    "\n",
    "#Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict missing 'd_ar' values where 'd_ar' is NaN but 'prev_d_dp' is not NaN\n",
    "missing_d_ar = (df['d_ar'].isna() & df['prev_d_dp'].notna())\n",
    "X_missing = df.loc[missing_d_ar, 'prev_d_dp'].values.reshape(-1, 1)\n",
    "\n",
    "# Impute 'd_ar_filled' only for the rows not in the exclusion set\n",
    "df.loc[missing_d_ar, 'd_ar_filled'] = model.predict(X_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85db75c2-bad5-43af-b604-0b7d49f2392b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04412128527449946)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.d_ar_filled.isna().sum()/len(df.d_ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3276a6b-e4b5-4479-9970-baf1974ade78",
   "metadata": {},
   "source": [
    "This gets our `d_ar` missing values down to 4%. Let's inspect the imputed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d204b83-25e5-429d-8e7d-ef2274ab57cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7625540    -3.000000\n",
       "1190917     4.833136\n",
       "6468721     4.833136\n",
       "1089867    18.279823\n",
       "1444543    46.133675\n",
       "1671656    54.777974\n",
       "5458307     8.675046\n",
       "1123366     0.000000\n",
       "6533332    -1.890208\n",
       "3776237    16.358868\n",
       "8609688     3.872658\n",
       "5711075    -2.850685\n",
       "8952858     5.793613\n",
       "1360051    -1.890208\n",
       "1873859          NaN\n",
       "5539155    -2.850685\n",
       "4454065     0.000000\n",
       "2168022     0.000000\n",
       "8890472     0.000000\n",
       "518143      2.912181\n",
       "Name: d_ar_filled, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.d_ar_filled.sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81251b66-6057-409b-a6e0-b368ca873b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8.581318e+06\n",
       "mean     1.330288e+01\n",
       "std      4.432669e+01\n",
       "min     -5.290000e+02\n",
       "25%     -1.890208e+00\n",
       "50%      3.074754e-02\n",
       "75%      1.000000e+01\n",
       "max      2.551000e+03\n",
       "Name: d_ar_filled, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.d_ar_filled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f7a4758-72a0-4214-8d98-3461dd6132e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGsCAYAAACB/u5dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAntklEQVR4nO3de3SU5YHH8d8kmQykMNzCJdGEmwWUACpomnoproRAKdV261pDtyx2qdVYdVFWaRdJSil4o+xxXWpvsJ5uoLIV3VoRIxpYBJRkQYlSBIpilYiBkiFEhyHz7B8eZp3mMu8kz9zC93NOTpx3nneeZ359h/l1LnldxhgjAAAAC9ISvQAAANB9UCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANQkrFlu2bNHMmTOVm5srl8ulp59+OurbMMbo4Ycf1qhRo+TxeHTeeedpyZIl9hcLAAAcyUjUxKdOndKECRN088036+tf/3qnbuPOO+/UCy+8oIcffljjxo3T8ePHdfz4ccsrBQAATrmS4SRkLpdL69ev1/XXXx/a5vf79cMf/lBr1qzRiRMnVFBQoAceeECTJ0+WJO3du1fjx49XXV2dRo8enZiFAwCAMEn7GYvbb79d27dv19q1a/XGG2/ohhtu0LRp07R//35J0u9//3uNGDFCzz77rIYPH65hw4bpH//xH3nFAgCABErKYnH48GGtWrVK69at01VXXaWRI0fqnnvu0ZVXXqlVq1ZJkv70pz/p3Xff1bp16/TEE09o9erVqq2t1Te+8Y0Erx4AgHNXwj5j0ZE9e/aopaVFo0aNCtvu9/s1YMAASVIwGJTf79cTTzwRGverX/1KEydO1L59+3h7BACABEjKYtHU1KT09HTV1tYqPT097LpevXpJknJycpSRkRFWPi688EJJn77iQbEAACD+krJYXHLJJWppadHRo0d11VVXtTnmiiuu0JkzZ3Tw4EGNHDlSkvT2229LkoYOHRq3tQIAgP+XsG+FNDU16cCBA5I+LRLLly/XNddco/79+ys/P1/f+ta39Morr+iRRx7RJZdcoo8++kibNm3S+PHjNWPGDAWDQV122WXq1auXVqxYoWAwqLKyMnm9Xr3wwguJuEsAAJzzElYsqqurdc0117TaPnv2bK1evVqBQEA//vGP9cQTT+j9999Xdna2vvCFL6iiokLjxo2TJH3wwQf6/ve/rxdeeEGf+9znNH36dD3yyCPq379/vO8OAABQkvwdCwAA0D0k5ddNAQBAaqJYAAAAa+L+rZBgMKgPPvhAvXv3lsvlivf0AACgE4wxOnnypHJzc5WW1v7rEnEvFh988IHy8vLiPS0AALDgvffe0/nnn9/u9XEvFr1795b06cK8Xm/M5gkEAnrhhRc0depUud3umM2T6sgpMjKKjIwiI6PIyMiZROXk8/mUl5cXeh5vT9yLxdm3P7xeb8yLRVZWlrxeLwdoB8gpMjKKjIwiI6PIyMiZROcU6WMMfHgTAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWxP206Qg37L4/JHR+T7rRg5dLBeUb5W/p+FS4Z72zbEaMVwUASFW8YgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAa6IqFi0tLVq4cKGGDx+unj17auTIkVq8eLGMMbFaHwAASCFR/R2LBx54QCtXrtR//Md/aOzYsaqpqdGcOXPUp08f3XHHHbFaIwAASBFRFYtt27bpuuuu04wZn/6BpGHDhmnNmjV67bXXYrI4AACQWqIqFl/84hf185//XG+//bZGjRql119/XVu3btXy5cvb3cfv98vv94cu+3w+SVIgEFAgEOjksiM7e9uxnMMGT3pi30bypJmw304ke6a2pcqxlEhkFBkZRUZGziQqJ6fzuUwUH5AIBoP6wQ9+oAcffFDp6elqaWnRkiVLtGDBgnb3KS8vV0VFRavtlZWVysrKcjo1AABIoObmZpWWlqqxsVFer7fdcVEVi7Vr12r+/Pl66KGHNHbsWO3evVt33XWXli9frtmzZ7e5T1uvWOTl5amhoaHDhXVVIBBQVVWViouL5Xa7YzZPVxWUb0zo/J40o8WTglpYkyZ/0Nm5QurKS2K8quSSKsdSIpFRZGQUGRk5k6icfD6fsrOzIxaLqN4KmT9/vu677z5985vflCSNGzdO7777rpYuXdpusfB4PPJ4PK22u93uuAQSr3k6y+mJv2LNH3Q5Xksy5xlLyX4sJQMyioyMIiMjZ+Kdk9O5ovq6aXNzs9LSwndJT09XMBiM5mYAAEA3FdUrFjNnztSSJUuUn5+vsWPHateuXVq+fLluvvnmWK0PAACkkKiKxaOPPqqFCxfqtttu09GjR5Wbm6tbbrlF999/f6zWBwAAUkhUxaJ3795asWKFVqxYEaPlAACAVMa5QgAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYE1WxGDZsmFwuV6ufsrKyWK0PAACkkIxoBu/cuVMtLS2hy3V1dSouLtYNN9xgfWEAACD1RFUsBg4cGHZ52bJlGjlypL70pS9ZXRQAAEhNURWLzzp9+rR+85vfaN68eXK5XO2O8/v98vv9ocs+n0+SFAgEFAgEOjt9RGdvO5Zz2OBJN4mdP82E/XYi2TO1LVWOpUQio8jIKDIyciZROTmdz2WM6dQz25NPPqnS0lIdPnxYubm57Y4rLy9XRUVFq+2VlZXKysrqzNQAACDOmpubVVpaqsbGRnm93nbHdbpYlJSUKDMzU7///e87HNfWKxZ5eXlqaGjocGFdFQgEVFVVpeLiYrnd7pjN01UF5RsTOr8nzWjxpKAW1qTJH2z/lafPqisvifGqkkuqHEuJREaRkVFkZORMonLy+XzKzs6OWCw69VbIu+++qxdffFFPPfVUxLEej0cej6fVdrfbHZdA4jVPZ/lbnD2Zx5o/6HK8lmTOM5aS/VhKBmQUGRlFRkbOxDsnp3N16u9YrFq1SoMGDdKMGTM6szsAAOimoi4WwWBQq1at0uzZs5WR0enPfgIAgG4o6mLx4osv6vDhw7r55ptjsR4AAJDCon7JYerUqerk5z0BAEA3x7lCAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZEXSzef/99fetb39KAAQPUs2dPjRs3TjU1NbFYGwAASDEZ0Qz+y1/+oiuuuELXXHONNmzYoIEDB2r//v3q169frNYHAABSSFTF4oEHHlBeXp5WrVoV2jZ8+HDriwIAAKkpqmLx3//93yopKdENN9ygzZs367zzztNtt92muXPntruP3++X3+8PXfb5fJKkQCCgQCDQyWVHdva2YzmHDZ50k9j500zYbyeSPVPbUuVYSiQyioyMIiMjZxKVk9P5XMYYx88oPXr0kCTNmzdPN9xwg3bu3Kk777xTP/vZzzR79uw29ykvL1dFRUWr7ZWVlcrKynI6NQAASKDm5maVlpaqsbFRXq+33XFRFYvMzExNmjRJ27ZtC2274447tHPnTm3fvr3Nfdp6xSIvL08NDQ0dLqyrAoGAqqqqVFxcLLfbHbN5uqqgfGNC5/ekGS2eFNTCmjT5gy5H+9SVl8R4VcklVY6lRCKjyMgoMjJyJlE5+Xw+ZWdnRywWUb0VkpOTo4suuihs24UXXqjf/e537e7j8Xjk8XhabXe73XEJJF7zdJa/xdmTeaz5gy7Ha0nmPGMp2Y+lZEBGkZFRZGTkTLxzcjpXVF83veKKK7Rv376wbW+//baGDh0azc0AAIBuKqpi8U//9E/asWOHfvKTn+jAgQOqrKzUz3/+c5WVlcVqfQAAIIVEVSwuu+wyrV+/XmvWrFFBQYEWL16sFStWaNasWbFaHwAASCFRfcZCkr7yla/oK1/5SizWAgAAUhznCgEAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYE1WxKC8vl8vlCvsZM2ZMrNYGAABSTEa0O4wdO1Yvvvji/99ARtQ3AQAAuqmoW0FGRoaGDBkSi7UAAIAUF3Wx2L9/v3Jzc9WjRw8VFRVp6dKlys/Pb3e83++X3+8PXfb5fJKkQCCgQCDQiSU7c/a2YzmHDZ50k9j500zYbyeSPVPbUuVYSiQyioyMIiMjZxKVk9P5XMYYx88oGzZsUFNTk0aPHq0jR46ooqJC77//vurq6tS7d+829ykvL1dFRUWr7ZWVlcrKynI6NQAASKDm5maVlpaqsbFRXq+33XFRFYu/duLECQ0dOlTLly/Xd77znTbHtPWKRV5enhoaGjpcWFcFAgFVVVWpuLhYbrc7ZvN0VUH5xoTO70kzWjwpqIU1afIHXY72qSsvifGqkkuqHEuJREaRkVFkZORMonLy+XzKzs6OWCy69MnLvn37atSoUTpw4EC7YzwejzweT6vtbrc7LoHEa57O8rc4ezKPNX/Q5XgtyZxnLCX7sZQMyCgyMoqMjJyJd05O5+rS37FoamrSwYMHlZOT05WbAQAA3URUxeKee+7R5s2b9c4772jbtm362te+pvT0dN10002xWh8AAEghUb0V8uc//1k33XSTjh07poEDB+rKK6/Ujh07NHDgwFitDwAApJCoisXatWtjtQ4AANANcK4QAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZ0qVgsW7ZMLpdLd911l6XlAACAVNbpYrFz5049/vjjGj9+vM31AACAFNapYtHU1KRZs2bpF7/4hfr162d7TQAAIEVldGansrIyzZgxQ1OmTNGPf/zjDsf6/X75/f7QZZ/PJ0kKBAIKBAKdmd6Rs7cdyzls8KSbxM6fZsJ+O5HsmdqWKsdSIpFRZGQUGRk5k6icnM7nMsZE9cy2du1aLVmyRDt37lSPHj00efJkXXzxxVqxYkWb48vLy1VRUdFqe2VlpbKysqKZGgAAJEhzc7NKS0vV2Ngor9fb7rioisV7772nSZMmqaqqKvTZikjFoq1XLPLy8tTQ0NDhwroqEAioqqpKxcXFcrvdMZunqwrKNyZ0fk+a0eJJQS2sSZM/6HK0T115SYxXlVxS5VhKJDKKjIwiIyNnEpWTz+dTdnZ2xGIR1VshtbW1Onr0qC699NLQtpaWFm3ZskX/9m//Jr/fr/T09LB9PB6PPB5Pq9tyu91xCSRe83SWv8XZk3ms+YMux2tJ5jxjKdmPpWRARpGRUWRk5Ey8c3I6V1TF4tprr9WePXvCts2ZM0djxozRvffe26pUAACAc0tUxaJ3794qKCgI2/a5z31OAwYMaLUdAACce/jLmwAAwJpOfd30s6qrqy0sAwAAdAe8YgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALCGYgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALCGYgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACwJqpisXLlSo0fP15er1der1dFRUXasGFDrNYGAABSTFTF4vzzz9eyZctUW1urmpoa/c3f/I2uu+46vfnmm7FaHwAASCEZ0QyeOXNm2OUlS5Zo5cqV2rFjh8aOHWt1YQAAIPVEVSw+q6WlRevWrdOpU6dUVFTU7ji/3y+/3x+67PP5JEmBQECBQKCz00d09rZjOYcNnnST2PnTTNhvJ5I9U9tS5VhKJDKKjIwiIyNnEpWT0/lcxpiontn27NmjoqIiffLJJ+rVq5cqKyv15S9/ud3x5eXlqqioaLW9srJSWVlZ0UwNAAASpLm5WaWlpWpsbJTX6213XNTF4vTp0zp8+LAaGxv1X//1X/rlL3+pzZs366KLLmpzfFuvWOTl5amhoaHDhXVVIBBQVVWViouL5Xa7YzZPVxWUb0zo/J40o8WTglpYkyZ/0OVon7rykhivKrmkyrGUSGQUGRlFRkbOJConn8+n7OzsiMUi6rdCMjMzdcEFF0iSJk6cqJ07d+pf//Vf9fjjj7c53uPxyOPxtNrudrvjEki85uksf4uzJ/NY8wddjteSzHnGUrIfS8mAjCIjo8jIyJl45+R0ri7/HYtgMBj2igQAADh3RfWKxYIFCzR9+nTl5+fr5MmTqqysVHV1tTZuTOzL+QAAIDlEVSyOHj2qb3/72zpy5Ij69Omj8ePHa+PGjSouLo7V+gAAQAqJqlj86le/itU6AABAN8C5QgAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWRFUsli5dqssuu0y9e/fWoEGDdP3112vfvn2xWhsAAEgxURWLzZs3q6ysTDt27FBVVZUCgYCmTp2qU6dOxWp9AAAghWREM/j5558Pu7x69WoNGjRItbW1uvrqq60uDAAApJ6oisVfa2xslCT179+/3TF+v19+vz902efzSZICgYACgUBXpu/Q2duO5Rw2eNJNYudPM2G/nUj2TG1LlWMpkcgoMjKKjIycSVROTudzGWM69cwWDAb11a9+VSdOnNDWrVvbHVdeXq6KiopW2ysrK5WVldWZqQEAQJw1NzertLRUjY2N8nq97Y7rdLG49dZbtWHDBm3dulXnn39+u+PaesUiLy9PDQ0NHS6sqwKBgKqqqlRcXCy32x2zebqqoHxjQuf3pBktnhTUwpo0+YMuR/vUlZfEeFXJJVWOpUQio8jIKDIyciZROfl8PmVnZ0csFp16K+T222/Xs88+qy1btnRYKiTJ4/HI4/G02u52u+MSSLzm6Sx/i7Mn81jzB12O15LMecZSsh9LyYCMIiOjyMjImXjn5HSuqIqFMUbf//73tX79elVXV2v48OGdWhwAAOieoioWZWVlqqys1DPPPKPevXurvr5ektSnTx/17NkzJgsEAACpI6q/Y7Fy5Uo1NjZq8uTJysnJCf389re/jdX6AABACon6rRAAAID2cK4QAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDVRF4stW7Zo5syZys3Nlcvl0tNPPx2DZQEAgFQUdbE4deqUJkyYoMceeywW6wEAACksI9odpk+frunTp8diLQAAIMVFXSyi5ff75ff7Q5d9Pp8kKRAIKBAIxGzes7cdyzls8KSbxM6fZsJ+O5HsmdqWKsdSIpFRZGQUGRk5k6icnM7nMsZ0+pnN5XJp/fr1uv7669sdU15eroqKilbbKysrlZWV1dmpAQBAHDU3N6u0tFSNjY3yer3tjot5sWjrFYu8vDw1NDR0uLCuCgQCqqqqUnFxsdxud8zm6aqC8o0Jnd+TZrR4UlALa9LkD7oc7VNXXhLjVSWXVDmWEomMIiOjyMjImUTl5PP5lJ2dHbFYxPytEI/HI4/H02q72+2OSyDxmqez/C3OnsxjzR90OV5LMucZS8l+LCUDMoqMjCIjI2finZPTufg7FgAAwJqoX7FoamrSgQMHQpcPHTqk3bt3q3///srPz7e6OAAAkFqiLhY1NTW65pprQpfnzZsnSZo9e7ZWr15tbWEAACD1RF0sJk+erC583hMAAHRjfMYCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1mQkegFIPcPu+0OilxC1d5bNSPQSAOCcwCsWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALCGYgEAAKyhWAAAAGs6VSwee+wxDRs2TD169FBhYaFee+012+sCAAApKOpi8dvf/lbz5s3TokWL9L//+7+aMGGCSkpKdPTo0VisDwAApJCoi8Xy5cs1d+5czZkzRxdddJF+9rOfKSsrS7/+9a9jsT4AAJBCojpXyOnTp1VbW6sFCxaEtqWlpWnKlCnavn17m/v4/X75/f7Q5cbGRknS8ePHFQgEOrNmRwKBgJqbm3Xs2DG53e6YzdNVGWdOJXb+oFFzc1AZgTS1BF0JXUssHTt2rNP7psqxlEhkFBkZRUZGziQqp5MnT0qSjDEdjouqWDQ0NKilpUWDBw8O2z548GD98Y9/bHOfpUuXqqKiotX24cOHRzM1Yqg00QuIg+xHEr0CAOgeTp48qT59+rR7fczPbrpgwQLNmzcvdDkYDOr48eMaMGCAXK7Y/T9kn8+nvLw8vffee/J6vTGbJ9WRU2RkFBkZRUZGkZGRM4nKyRijkydPKjc3t8NxURWL7Oxspaen68MPPwzb/uGHH2rIkCFt7uPxeOTxeMK29e3bN5ppu8Tr9XKAOkBOkZFRZGQUGRlFRkbOJCKnjl6pOCuqD29mZmZq4sSJ2rRpU2hbMBjUpk2bVFRUFP0KAQBAtxL1WyHz5s3T7NmzNWnSJF1++eVasWKFTp06pTlz5sRifQAAIIVEXSxuvPFGffTRR7r//vtVX1+viy++WM8//3yrD3Qmmsfj0aJFi1q9DYNw5BQZGUVGRpGRUWRk5Eyy5+Qykb43AgAA4BDnCgEAANZQLAAAgDUUCwAAYA3FAgAAWNMtisWwYcPkcrnCfpYtWxY25o033tBVV12lHj16KC8vTw8++GCr21m3bp3GjBmjHj16aNy4cXruuefidRcS4rHHHtOwYcPUo0cPFRYW6rXXXkv0kuKmvLy81TEzZsyY0PWffPKJysrKNGDAAPXq1Ut/+7d/2+oPwx0+fFgzZsxQVlaWBg0apPnz5+vMmTPxvivWbNmyRTNnzlRubq5cLpeefvrpsOuNMbr//vuVk5Ojnj17asqUKdq/f3/YmOPHj2vWrFnyer3q27evvvOd76ipqSlsjJPHYrKKlNE//MM/tDqupk2bFjamu2e0dOlSXXbZZerdu7cGDRqk66+/Xvv27QsbY+vxVV1drUsvvVQej0cXXHCBVq9eHeu7Z4WTjCZPntzqWPre974XNiZpMzLdwNChQ82PfvQjc+TIkdBPU1NT6PrGxkYzePBgM2vWLFNXV2fWrFljevbsaR5//PHQmFdeecWkp6ebBx980Lz11lvmX/7lX4zb7TZ79uxJxF2KubVr15rMzEzz61//2rz55ptm7ty5pm/fvubDDz9M9NLiYtGiRWbs2LFhx8xHH30Uuv573/ueycvLM5s2bTI1NTXmC1/4gvniF78Yuv7MmTOmoKDATJkyxezatcs899xzJjs72yxYsCARd8eK5557zvzwhz80Tz31lJFk1q9fH3b9smXLTJ8+fczTTz9tXn/9dfPVr37VDB8+3Hz88cehMdOmTTMTJkwwO3bsMP/zP/9jLrjgAnPTTTeFrnfyWExmkTKaPXu2mTZtWthxdfz48bAx3T2jkpISs2rVKlNXV2d2795tvvzlL5v8/Pywf5NtPL7+9Kc/maysLDNv3jzz1ltvmUcffdSkp6eb559/Pq73tzOcZPSlL33JzJ07N+xYamxsDF2fzBl1m2Lx05/+tN3r//3f/93069fP+P3+0LZ7773XjB49OnT57/7u78yMGTPC9issLDS33HKL9fUmg8svv9yUlZWFLre0tJjc3FyzdOnSBK4qfhYtWmQmTJjQ5nUnTpwwbrfbrFu3LrRt7969RpLZvn27MebTJ5i0tDRTX18fGrNy5Urj9XrDjrNU9ddPmsFg0AwZMsQ89NBDoW0nTpwwHo/HrFmzxhhjzFtvvWUkmZ07d4bGbNiwwbhcLvP+++8bY5w9FlNFe8Xiuuuua3efcy0jY4w5evSokWQ2b95sjLH3+Prnf/5nM3bs2LC5brzxRlNSUhLru2TdX2dkzKfF4s4772x3n2TOqFu8FSJJy5Yt04ABA3TJJZfooYceCns5aPv27br66quVmZkZ2lZSUqJ9+/bpL3/5S2jMlClTwm6zpKSk3dPBp7LTp0+rtrY27P6mpaVpypQp3fL+tmf//v3Kzc3ViBEjNGvWLB0+fFiSVFtbq0AgEJbPmDFjlJ+fH8pn+/btGjduXNgfhispKZHP59Obb74Z3zsSB4cOHVJ9fX1YJn369FFhYWFYJn379tWkSZNCY6ZMmaK0tDS9+uqroTGRHouprrq6WoMGDdLo0aN166236tixY6HrzsWMGhsbJUn9+/eXZO/x1Z3+zf7rjM76z//8T2VnZ6ugoEALFixQc3Nz6LpkzijmZzeNhzvuuEOXXnqp+vfvr23btmnBggU6cuSIli9fLkmqr69vdZr2s/9j1NfXq1+/fqqvr2/zdPD19fXxuRNx1NDQoJaWljbv7x//+McErSq+CgsLtXr1ao0ePVpHjhxRRUWFrrrqKtXV1am+vl6ZmZmtTpb32eOhvePl7HXdzdn71NFjpL6+XoMGDQq7PiMjQ/379w8bE+mxmMqmTZumr3/96xo+fLgOHjyoH/zgB5o+fbq2b9+u9PT0cy6jYDCou+66S1dccYUKCgokydrjq70xPp9PH3/8sXr27BmLu2RdWxlJUmlpqYYOHarc3Fy98cYbuvfee7Vv3z499dRTkpI7o6QtFvfdd58eeOCBDsfs3btXY8aMCTst+/jx45WZmalbbrlFS5cuTdo/eYrEmj59eui/x48fr8LCQg0dOlRPPvlkyvyDhOTzzW9+M/Tf48aN0/jx4zVy5EhVV1fr2muvTeDKEqOsrEx1dXXaunVropeStNrL6Lvf/W7ov8eNG6ecnBxde+21OnjwoEaOHBnvZUYlad8Kufvuu7V3794Of0aMGNHmvoWFhTpz5ozeeecdSdKQIUPaPNX72es6GtPe6eBTWXZ2ttLT08+Z++tE3759NWrUKB04cEBDhgzR6dOndeLEibAxn83HyTHVnZy9Tx0dM0OGDNHRo0fDrj9z5oyOHz9+zuY2YsQIZWdn68CBA5LOrYxuv/12Pfvss3r55Zd1/vnnh7bbeny1N8br9abM/zloL6O2FBYWSlLYsZSsGSVtsRg4cKDGjBnT4c9n34P8rN27dystLS30kmNRUZG2bNmiQCAQGlNVVaXRo0eHXlYsKioKOx382THd8XTwmZmZmjhxYtj9DQaD2rRpU7e8v040NTXp4MGDysnJ0cSJE+V2u8Py2bdvnw4fPhzKp6ioSHv27Al7kqiqqpLX69VFF10U9/XH2vDhwzVkyJCwTHw+n1599dWwTE6cOKHa2trQmJdeeknBYDD0j6KTx2J38uc//1nHjh1TTk6OpHMjI2OMbr/9dq1fv14vvfRSq7d1bD2+Uvnf7EgZtWX37t2SFHYsJW1GMf1oaBxs27bN/PSnPzW7d+82Bw8eNL/5zW/MwIEDzbe//e3QmBMnTpjBgwebv//7vzd1dXVm7dq1Jisrq9XXTTMyMszDDz9s9u7daxYtWtTtv27q8XjM6tWrzVtvvWW++93vmr59+4Z9wrg7u/vuu011dbU5dOiQeeWVV8yUKVNMdna2OXr0qDHm06/D5efnm5deesnU1NSYoqIiU1RUFNr/7Fe9pk6danbv3m2ef/55M3DgwJT+uunJkyfNrl27zK5du4wks3z5crNr1y7z7rvvGmM+/bpp3759zTPPPGPeeOMNc91117X5ddNLLrnEvPrqq2br1q3m85//fNhXKZ08FpNZRxmdPHnS3HPPPWb79u3m0KFD5sUXXzSXXnqp+fznP28++eST0G1094xuvfVW06dPH1NdXR32Vcnm5ubQGBuPr7NfpZw/f77Zu3eveeyxx1Lm66aRMjpw4ID50Y9+ZGpqasyhQ4fMM888Y0aMGGGuvvrq0G0kc0YpXyxqa2tNYWGh6dOnj+nRo4e58MILzU9+8pOwB7Ixxrz++uvmyiuvNB6Px5x33nlm2bJlrW7rySefNKNGjTKZmZlm7Nix5g9/+EO87kZCPProoyY/P99kZmaayy+/3OzYsSPRS4qbG2+80eTk5JjMzExz3nnnmRtvvNEcOHAgdP3HH39sbrvtNtOvXz+TlZVlvva1r5kjR46E3cY777xjpk+fbnr27Gmys7PN3XffbQKBQLzvijUvv/yykdTqZ/bs2caYT79yunDhQjN48GDj8XjMtddea/bt2xd2G8eOHTM33XST6dWrl/F6vWbOnDnm5MmTYWOcPBaTVUcZNTc3m6lTp5qBAwcat9tthg4daubOnduqrHf3jNrKR5JZtWpVaIytx9fLL79sLr74YpOZmWlGjBgRNkcyi5TR4cOHzdVXX2369+9vPB6PueCCC8z8+fPD/o6FMcmbEadNBwAA1iTtZywAAEDqoVgAAABrKBYAAMAaigUAALCGYgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACw5v8Ac8k9Ot9j+oIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.d_ar_filled.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ff5e4-340d-4761-9350-d42fd8232b66",
   "metadata": {},
   "source": [
    "Looks like there are some outliers, so we may have to remove those in any steps where we use linear regression. Nonlinear regression techniques will be fine as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd270011-d685-41e4-94c3-f0868f67a3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                          0\n",
       "origin_date                 0\n",
       "sta_no                      0\n",
       "station                     0\n",
       "origin_day_of_week          0\n",
       "updated                     0\n",
       "prev_origin_date            1\n",
       "prev_no                     1\n",
       "comments               107903\n",
       "d_ar_filled            396095\n",
       "prev_sta_no            446377\n",
       "schDpDay               635801\n",
       "schDp                  635803\n",
       "prev_schDp             635815\n",
       "prev_d_dp              929672\n",
       "d_dp                   929672\n",
       "actDp                  930013\n",
       "schAr                 1915773\n",
       "schAr_filled          2819218\n",
       "actAr                 5921889\n",
       "d_ar                  5922086\n",
       "schArDay              6774767\n",
       "prev_schAr            6774873\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "442d7047-3e91-4753-a451-b442db35e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('AmtrakDataImputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0074505-eaed-46e0-ba5e-c088d8574efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8977413, 23)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9773e3f-9555-43e4-97ec-85cb4fb30224",
   "metadata": {},
   "source": [
    "<h2>Feature Engineering<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d7622-e7ac-42f5-87c3-d2788169f387",
   "metadata": {},
   "source": [
    "<h3>Train & Station Features<h3>\n",
    "\n",
    "- no\n",
    "- sta_no\n",
    "- Train Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1e07c-6fd0-4345-b291-316d97a3dbc0",
   "metadata": {},
   "source": [
    "We should convert `no` and `sta_no` into categoricals for final prediction to avoid the inference of a numerical relationship. Once we take care of that, however, these features will be important to included to catch whether a certain train or station tends to have more delays. For example, long distance trains traveling coast to coast have a higher chance of encountering a crossing with freight trains, a case in which they can experience major delays. This will help to catch that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26732f1c-4222-4187-adaf-a33317d3d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "982fed88-a3a4-4c73-a7b6-95e9b0c52a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no'] = df['no'].astype(str)\n",
    "df['sta_no'] = df['sta_no'].astype(str)\n",
    "X = pd.concat([X, df[['no','sta_no']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe49f9-e053-44e5-a7b7-43f1b4390290",
   "metadata": {},
   "source": [
    "Amtrak organizes their trains into three groups: Northeast Corridor (NEC), State-Supported, and Long Distance. NEC trains, especially Acela trains, are least prone to delay. State-Supported next least, and Long Distance the most. As described above, Long Distance trains are most prone to delays because they intersect with freight trains. Let's add train categories for:\n",
    "- NEC Acela\n",
    "- NEC Regional\n",
    "- State Supported\n",
    "- Long Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e95691f1-f271-4d52-ae6d-b1cce78520c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>sta_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     no sta_no\n",
       "2503  1    1.0\n",
       "2504  1    2.0\n",
       "2505  1    3.0\n",
       "2506  1    4.0\n",
       "2507  1    5.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737406dc-91c6-4d41-ab01-fda2ef9a401b",
   "metadata": {},
   "source": [
    "<h3>Date Transformation Features<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d044a7-d1ef-49db-a3d8-6542312fead5",
   "metadata": {},
   "source": [
    "`origin_date`\n",
    "\n",
    "- Day of Week (weekly seasonality)\n",
    "- Day of Month (monthly seasonality)\n",
    "- Month of Year (yearly seasonality)\n",
    "- Days since beginning (track change over time)\n",
    "\n",
    "`schDpDay`\n",
    "- Catch any tendency for more or less delay on later days of journey. (Not independent from `sta_no`, so maybe leave out of initial predictive analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce5d75-4966-448b-9995-a29dcfd4c5e6",
   "metadata": {},
   "source": [
    "<h3>Date Transformation Features<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f5923af-6bb2-4c97-8919-6794d6f6e614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>sta_no</th>\n",
       "      <th>station</th>\n",
       "      <th>schArDay</th>\n",
       "      <th>schAr</th>\n",
       "      <th>actAr</th>\n",
       "      <th>schDpDay</th>\n",
       "      <th>schDp</th>\n",
       "      <th>actDp</th>\n",
       "      <th>...</th>\n",
       "      <th>comments</th>\n",
       "      <th>updated</th>\n",
       "      <th>prev_schDp</th>\n",
       "      <th>prev_schAr</th>\n",
       "      <th>prev_no</th>\n",
       "      <th>prev_origin_date</th>\n",
       "      <th>prev_sta_no</th>\n",
       "      <th>origin_day_of_week</th>\n",
       "      <th>schAr_filled</th>\n",
       "      <th>prev_d_dp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NOL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-11 09:00:00</td>\n",
       "      <td>2024-10-11 09:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 09:00:00</td>\n",
       "      <td>2024-10-11 09:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Departed:  On time.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-11 09:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 10:30:00</td>\n",
       "      <td>2024-10-11 13:27:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Departed:  2 hours, 57 minutes late.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "      <td>2018-01-01 09:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NIB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 11:56:00</td>\n",
       "      <td>2024-10-11 14:45:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Departed:  2 hours, 49 minutes late.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "      <td>2018-01-01 10:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LFT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 12:24:00</td>\n",
       "      <td>2024-10-11 15:07:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 12:24:00</td>\n",
       "      <td>2024-10-11 15:13:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Arrived:  2 hours, 43 minutes late.  |  Depart...</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "      <td>2018-01-01 11:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 12:24:00</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>LCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 13:55:00</td>\n",
       "      <td>2024-10-11 16:49:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Departed:  2 hours, 54 minutes late.</td>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "      <td>2018-01-01 12:24:00</td>\n",
       "      <td>2018-01-01 12:24:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      no origin_date  sta_no station  schArDay               schAr  \\\n",
       "2503   1  2018-01-01     1.0     NOL       NaN 2024-10-11 09:00:00   \n",
       "2504   1  2018-01-01     2.0     SCH       NaN                 NaT   \n",
       "2505   1  2018-01-01     3.0     NIB       NaN                 NaT   \n",
       "2506   1  2018-01-01     4.0     LFT       1.0 2018-01-01 12:24:00   \n",
       "2507   1  2018-01-01     5.0     LCH       NaN                 NaT   \n",
       "\n",
       "                   actAr  schDpDay               schDp               actDp  \\\n",
       "2503 2024-10-11 09:00:00       1.0 2018-01-01 09:00:00 2024-10-11 09:00:00   \n",
       "2504                 NaT       1.0 2018-01-01 10:30:00 2024-10-11 13:27:00   \n",
       "2505                 NaT       1.0 2018-01-01 11:56:00 2024-10-11 14:45:00   \n",
       "2506 2024-10-11 15:07:00       1.0 2018-01-01 12:24:00 2024-10-11 15:13:00   \n",
       "2507                 NaT       1.0 2018-01-01 13:55:00 2024-10-11 16:49:00   \n",
       "\n",
       "      ...                                           comments  \\\n",
       "2503  ...                                Departed:  On time.   \n",
       "2504  ...               Departed:  2 hours, 57 minutes late.   \n",
       "2505  ...               Departed:  2 hours, 49 minutes late.   \n",
       "2506  ...  Arrived:  2 hours, 43 minutes late.  |  Depart...   \n",
       "2507  ...               Departed:  2 hours, 54 minutes late.   \n",
       "\n",
       "                  updated           prev_schDp           prev_schAr prev_no  \\\n",
       "2503  2019-03-26 00:00:00                 None                 None     NaN   \n",
       "2504  2019-03-26 00:00:00  2018-01-01 09:00:00                  NaN     1.0   \n",
       "2505  2019-03-26 00:00:00  2018-01-01 10:30:00                  NaN     1.0   \n",
       "2506  2019-03-26 00:00:00  2018-01-01 11:56:00                  NaN     1.0   \n",
       "2507  2019-03-26 00:00:00  2018-01-01 12:24:00  2018-01-01 12:24:00     1.0   \n",
       "\n",
       "     prev_origin_date  prev_sta_no origin_day_of_week        schAr_filled  \\\n",
       "2503             None          NaN                  0 2024-10-11 09:00:00   \n",
       "2504       2018-01-01          1.0                  0                 NaT   \n",
       "2505       2018-01-01          2.0                  0                 NaT   \n",
       "2506       2018-01-01          3.0                  0 2018-01-01 12:24:00   \n",
       "2507       2018-01-01          4.0                  0                 NaT   \n",
       "\n",
       "      prev_d_dp  \n",
       "2503        NaN  \n",
       "2504        0.0  \n",
       "2505      177.0  \n",
       "2506      169.0  \n",
       "2507      169.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea782086-f52f-4ff1-8400-d54e6174b230",
   "metadata": {},
   "source": [
    "<h2>Training & Prediction<h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
